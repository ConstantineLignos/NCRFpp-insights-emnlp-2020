# What's contained here

This contains all code needed to replicate the experiments
from the paper
[If You Build Your Own NER Scorer, Non-replicable Results Will Come](https://www.aclweb.org/anthology/2020.insights-1.15/).
This is a fork of NCRF++, so there are many other files. The vast
majority of files are from the original repository.  README.orig.md
contains the README from the original repository.

# Looking at raw scores

We have provided the raw TSVs generated for each of the 120 runs we
performed in `exp_logs`, along with a merged version in
`exp_logs/merged.tsv`.

You can use the R script `analysis/analyze_f1.R` to explore the data.

# Replication

To replicate the experiments run in this paper, do the following:

1. Install Anaconda.
   Create the environment: `conda env create -f environment.yml`.
   Activate it: `conda activate ncrfpp`.

2. Put the the GloVe 6B 50d word vectors at
   `embeddings/glove.6B.50d.txt` Populate the files
   `clean_data/en/{train,dev,test}.txt.clean` using CoNLL 2003 English
   files in the BIO encoding with all columns removed except the token
   and label. Similarly, populate
   `clean_data/en/{train,dev,test}.txt.clean.bioes` using CoNLL 2003
   English files in the BIOES encoding with all columns removed except
   the token and label. The files should look like this (BIO then
   BIOES):

```
-DOCSTART- O

EU B-ORG
rejects O
German B-MISC
call O
to O
boycott O
British B-MISC
lamb O
. O
```

```
-DOCSTART- O

EU S-ORG
rejects O
German S-MISC
call O
to O
boycott O
British S-MISC
lamb O
. O
```

3. Run `run_eval_exps_conll_eng.sh <config file>` once for each of the
   six configuration files in `exp_configs`.  Each run of the script
   uses 10 CPUs in parallel (for greater parallelism, we use CPUs
   instead of GPUs), and will take a few hours. (We have set up the
   scripts such that interrupting them will kill all 10 runs, but this
   feature causes your script to exit prematurely if you write a
   script that calls our run script. You can remove the `trap`
   directives to fix this.

4. Run `./merge_tsv.sh` which will combine the TSV files generated by
   individual experiments into `exp_logs/merged.tsv`.

Enjoy, and thank you for looking at our replication materials!

Constantine Lignos (lastname at brandeis.edu) and Marjan Kamyab
